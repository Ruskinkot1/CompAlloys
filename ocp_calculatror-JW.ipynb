{
 "cells": [
  {
   "cell_type": "code",
   "id": "5bae9be4d3c2394c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-11T15:34:29.555489Z"
    }
   },
   "source": [
    "import os\n",
    "import random\n",
    "from ase.build import bulk, molecule, add_adsorbate, surface\n",
    "from ase import Atoms\n",
    "from ase.io.vasp import write_vasp\n",
    "from ase.optimize import LBFGS\n",
    "from ase.io import Trajectory\n",
    "from ase.constraints import FixAtoms\n",
    "from fairchem.core.trainers.ocp_trainer import OCPTrainer\n",
    "import fairchem.core.models.equiformer_v2.trainers.forces_trainer as forces_trainer \n",
    "from fairchem.core import OCPCalculator  \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Configuration\n",
    "elements = ['Co', 'Ni', 'Pd', 'Rh', 'Ru']  # Example elements\n",
    "slab_size = (6, 6, 3)\n",
    "num_samples = 2000\n",
    "main_output_dir = \"outputs\"\n",
    "os.makedirs(main_output_dir, exist_ok=True)\n",
    "\n",
    "# Input/output directories for raw and relaxed structures\n",
    "input_dir = os.path.join(\"data\", \"input\")\n",
    "output_dir = os.path.join(\"data\", \"output\")\n",
    "os.makedirs(input_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Adsorbate definitions\n",
    "adsorbate_names = ['CH4', 'CH3', 'CO', 'CO2', 'CH', 'C', 'HCO', 'CH3O', 'H', 'H2', 'H2O', 'OH']\n",
    "adsorbates = {name: molecule(name) for name in adsorbate_names}\n",
    "adsorbates.update({\n",
    "    'CH2': Atoms('CH2', positions=[[0,0,0], [0,0,1.09], [0,0,-1.09]]),\n",
    "    'O': Atoms('O', positions=[[0,0,0]]),\n",
    "    'HCOO': Atoms('HCOO', positions=[[0,0,0], [0,0,1.23], [0,0,-1.23], [0,0,1.0]]),\n",
    "    'COOH': Atoms('COOH', positions=[[0,0,0], [0,0,1.23], [0,0,-1.23], [0,0.97,-1.23]]),\n",
    "    'CH2O': Atoms('CH2O', positions=[[0,0,0], [0,0,1.21], [0,0.94,-0.54], [0,-0.94,-0.54]])\n",
    "})\n",
    "\n",
    "# Adsorption sites (relative positions on the surface)\n",
    "positions = [(6,6), (6,7), (5,7), (7,5), (5,6), (6,5), (5,5), (7,7)]\n",
    "\n",
    "# Placeholder for results\n",
    "results = []\n",
    "\n",
    "# Define your calculator\n",
    "calc = OCPCalculator(\n",
    "    model_name=\"EquiformerV2-83M-S2EF-OC20-2M\",\n",
    "    local_cache=\"pretrained_models\",\n",
    "    cpu=False\n",
    ")\n",
    "\n",
    "# Generate slabs â€” you need to define this function\n",
    "def generate_hea_slabs(elements, slab_size, num_samples):\n",
    "    num_atoms = slab_size[0] * slab_size[1] * slab_size[2]\n",
    "    slabs = set()\n",
    "\n",
    "    while len(slabs) < num_samples:\n",
    "        composition = [random.choice(elements) for _ in range(num_atoms)]\n",
    "        composition_tuple = tuple(sorted(composition))\n",
    "\n",
    "        if composition_tuple not in slabs:\n",
    "            slabs.add(composition_tuple)\n",
    "\n",
    "            base_structure = bulk(elements[0], 'fcc', a=3.9)\n",
    "            slab_structure = surface(base_structure, (1, 1, 1), layers=slab_size[2]).repeat((slab_size[0], slab_size[1], 1))\n",
    "            for atom, element in zip(slab_structure, composition):\n",
    "                atom.symbol = element\n",
    "            yield slab_structure\n",
    "# Main loop\n",
    "i=0\n",
    "for slab in tqdm(generate_hea_slabs(elements, slab_size, num_samples)):\n",
    "    i=i+1\n",
    "    combo_name = \"\".join(str(slab.get_chemical_formula())) + \"-FCC\"\n",
    "    combo_dir = os.path.join(main_output_dir, combo_name)\n",
    "    os.makedirs(combo_dir, exist_ok=True)\n",
    "\n",
    "    slab.set_pbc([True, True, False])\n",
    "\n",
    "    for ads_name, ads in adsorbates.items():\n",
    "        \n",
    "        for pos in positions:\n",
    "            # File paths\n",
    "            traj_path = os.path.join(combo_dir, f\"slab_{i+1}_{ads_name}_{pos[0]}_{pos[1]}.traj\")\n",
    "            poscar_filename = os.path.join(output_dir, f\"relaxed_slab_{i+1}_{ads_name}_{pos[0]}_{pos[1]}.vasp\")\n",
    "            input_filename = os.path.join(input_dir, f\"input_slab_{i+1}_{ads_name}_{pos[0]}_{pos[1]}.vasp\")\n",
    "\n",
    "            # Copy and modify structure\n",
    "            slab_ads = slab.copy()\n",
    "            add_adsorbate(slab_ads, ads, height=1.8, position=pos)\n",
    "            slab_ads.center(axis=2, vacuum=10)\n",
    "            constraint = FixAtoms(indices=range(len(slab)))\n",
    "            slab_ads.set_constraint(constraint)\n",
    "            slab_ads.calc = calc\n",
    "\n",
    "            # Save structure before relaxation\n",
    "            write_vasp(input_filename, slab_ads, direct=True, sort=True, vasp5=True)\n",
    "\n",
    "            # Relax the system\n",
    "            dyn = LBFGS(slab_ads, trajectory=traj_path)\n",
    "            dyn.run(fmax=0.05, steps=200)\n",
    "\n",
    "            # Get energy and save relaxed structure\n",
    "            energy = slab_ads.get_potential_energy()\n",
    "            write_vasp(poscar_filename, slab_ads, direct=True, sort=True, vasp5=True)\n",
    "\n",
    "            # Record result\n",
    "            results.append({\n",
    "                \"slab_index\": i+1,\n",
    "                \"element_combo\": \"-\".join(slab.get_chemical_formula()),\n",
    "                \"adsorbate\": ads_name,\n",
    "                \"position\": pos,\n",
    "                \"energy\": energy,\n",
    "                \"traj_file\": traj_path,\n",
    "                \"input_file\": input_filename,\n",
    "                \"output_file\": poscar_filename\n",
    "            })\n",
    "\n",
    "    # Periodic saving\n",
    "    if (i + 1) % 50 == 0:\n",
    "        df_results = pd.DataFrame(results)\n",
    "        df_results.to_csv(os.path.join(main_output_dir, \"energy_results.csv\"), index=False)\n",
    "        print(f\"Processed {i+1} slabs. Current combo: {combo_name}\")\n",
    "\n",
    "# Final save\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(os.path.join(main_output_dir, \"energy_results.csv\"), index=False)\n",
    "print(\"All tasks completed.\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/HEA/lib/python3.12/site-packages/fairchem/core/models/scn/spherical_harmonics.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  _Jd = torch.load(os.path.join(os.path.dirname(__file__), \"Jd.pt\"))\n",
      "/home/user/anaconda3/envs/HEA/lib/python3.12/site-packages/fairchem/core/models/equiformer_v2/wigner.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  _Jd = torch.load(os.path.join(os.path.dirname(__file__), \"Jd.pt\"))\n",
      "/home/user/anaconda3/envs/HEA/lib/python3.12/site-packages/fairchem/core/models/escn/so3.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  _Jd = torch.load(os.path.join(os.path.dirname(__file__), \"Jd.pt\"))\n",
      "INFO:root:Checking local cache: pretrained_models for model EquiformerV2-83M-S2EF-OC20-2M\n",
      "/home/user/anaconda3/envs/HEA/lib/python3.12/site-packages/fairchem/core/common/relaxation/ase_utils.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n",
      "WARNING:root:Detected old config, converting to new format. Consider updating to avoid potential incompatibilities.\n",
      "INFO:root:local rank base: 0\n",
      "INFO:root:amp: true\n",
      "cmd:\n",
      "  checkpoint_dir: /home/user/CompAlloys/checkpoints/2025-05-11-18-34-24\n",
      "  commit: core:None,experimental:NA\n",
      "  identifier: ''\n",
      "  logs_dir: /home/user/CompAlloys/logs/wandb/2025-05-11-18-34-24\n",
      "  print_every: 100\n",
      "  results_dir: /home/user/CompAlloys/results/2025-05-11-18-34-24\n",
      "  seed: null\n",
      "  timestamp_id: 2025-05-11-18-34-24\n",
      "  version: 1.10.0\n",
      "dataset:\n",
      "  format: trajectory_lmdb_v2\n",
      "  grad_target_mean: 0.0\n",
      "  grad_target_std: 2.887317180633545\n",
      "  key_mapping:\n",
      "    force: forces\n",
      "    y: energy\n",
      "  normalize_labels: true\n",
      "  target_mean: -0.7554450631141663\n",
      "  target_std: 2.887317180633545\n",
      "  transforms:\n",
      "    normalizer:\n",
      "      energy:\n",
      "        mean: -0.7554450631141663\n",
      "        stdev: 2.887317180633545\n",
      "      forces:\n",
      "        mean: 0.0\n",
      "        stdev: 2.887317180633545\n",
      "evaluation_metrics:\n",
      "  metrics:\n",
      "    energy:\n",
      "    - mae\n",
      "    forces:\n",
      "    - forcesx_mae\n",
      "    - forcesy_mae\n",
      "    - forcesz_mae\n",
      "    - mae\n",
      "    - cosine_similarity\n",
      "    - magnitude_error\n",
      "    misc:\n",
      "    - energy_forces_within_threshold\n",
      "  primary_metric: forces_mae\n",
      "gp_gpus: null\n",
      "gpus: 1\n",
      "logger: wandb\n",
      "loss_functions:\n",
      "- energy:\n",
      "    coefficient: 2\n",
      "    fn: mae\n",
      "- forces:\n",
      "    coefficient: 100\n",
      "    fn: l2mae\n",
      "model:\n",
      "  alpha_drop: 0.1\n",
      "  attn_activation: silu\n",
      "  attn_alpha_channels: 64\n",
      "  attn_hidden_channels: 64\n",
      "  attn_value_channels: 16\n",
      "  distance_function: gaussian\n",
      "  drop_path_rate: 0.05\n",
      "  edge_channels: 128\n",
      "  ffn_activation: silu\n",
      "  ffn_hidden_channels: 128\n",
      "  grid_resolution: 18\n",
      "  lmax_list:\n",
      "  - 6\n",
      "  max_neighbors: 20\n",
      "  max_num_elements: 90\n",
      "  max_radius: 12.0\n",
      "  mmax_list:\n",
      "  - 2\n",
      "  name: equiformer_v2\n",
      "  norm_type: layer_norm_sh\n",
      "  num_distance_basis: 512\n",
      "  num_heads: 8\n",
      "  num_layers: 12\n",
      "  num_sphere_samples: 128\n",
      "  otf_graph: true\n",
      "  proj_drop: 0.0\n",
      "  regress_forces: true\n",
      "  share_atom_edge_embedding: false\n",
      "  sphere_channels: 128\n",
      "  use_atom_edge_embedding: true\n",
      "  use_attn_renorm: true\n",
      "  use_gate_act: false\n",
      "  use_grid_mlp: true\n",
      "  use_pbc: true\n",
      "  use_s2_act_attn: false\n",
      "  use_sep_s2_act: true\n",
      "  weight_init: uniform\n",
      "optim:\n",
      "  batch_size: 4\n",
      "  clip_grad_norm: 100\n",
      "  ema_decay: 0.999\n",
      "  energy_coefficient: 2\n",
      "  eval_batch_size: 4\n",
      "  eval_every: 5000\n",
      "  force_coefficient: 100\n",
      "  grad_accumulation_steps: 1\n",
      "  load_balancing: atoms\n",
      "  loss_energy: mae\n",
      "  loss_force: l2mae\n",
      "  lr_initial: 0.0004\n",
      "  max_epochs: 30\n",
      "  num_workers: 8\n",
      "  optimizer: AdamW\n",
      "  optimizer_params:\n",
      "    weight_decay: 0.001\n",
      "  scheduler: LambdaLR\n",
      "  scheduler_params:\n",
      "    epochs: 468750\n",
      "    lambda_type: cosine\n",
      "    lr: 0.0004\n",
      "    lr_min_factor: 0.01\n",
      "    warmup_epochs: 1562.5\n",
      "    warmup_factor: 0.2\n",
      "outputs:\n",
      "  energy:\n",
      "    level: system\n",
      "  forces:\n",
      "    eval_on_free_atoms: true\n",
      "    level: atom\n",
      "    train_on_free_atoms: true\n",
      "relax_dataset: {}\n",
      "slurm:\n",
      "  additional_parameters:\n",
      "    constraint: volta32gb\n",
      "  cpus_per_task: 9\n",
      "  folder: /checkpoint/abhshkdz/open-catalyst-project/logs/equiformer_v2/6600242\n",
      "  gpus_per_node: 8\n",
      "  job_id: '6600242'\n",
      "  job_name: eq2s_2_9_041701_2M\n",
      "  mem: 480GB\n",
      "  nodes: 4\n",
      "  ntasks_per_node: 8\n",
      "  partition: ocp,learnaccel\n",
      "  time: 4320\n",
      "task:\n",
      "  dataset: trajectory_lmdb_v2\n",
      "  eval_on_free_atoms: true\n",
      "  grad_input: atomic forces\n",
      "  labels:\n",
      "  - potential energy\n",
      "  primary_metric: forces_mae\n",
      "  train_on_free_atoms: true\n",
      "test_dataset: {}\n",
      "trainer: ocp\n",
      "val_dataset: {}\n",
      "\n",
      "INFO:root:Loading model: equiformer_v2\n",
      "WARNING:root:equiformer_v2 (EquiformerV2) class is deprecated in favor of equiformer_v2_backbone_and_heads  (EquiformerV2BackboneAndHeads)\n",
      "INFO:root:Loaded EquiformerV2 with 83164802 parameters.\n",
      "INFO:root:Loading checkpoint in inference-only mode, not loading keys associated with trainer state!\n",
      "/home/user/anaconda3/envs/HEA/lib/python3.12/site-packages/fairchem/core/modules/normalization/normalizer.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"mean\": torch.tensor(state_dict[\"mean\"]),\n",
      "WARNING:root:No seed has been set in modelcheckpoint or OCPCalculator! Results may not be reproducible on re-run\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Step     Time          Energy          fmax\n",
      "LBFGS:    0 18:34:34        9.871245       12.179557\n",
      "LBFGS:    1 18:34:34        7.844672        5.910814\n",
      "LBFGS:    2 18:34:34        6.863335        2.274467\n",
      "LBFGS:    3 18:34:34        6.466945        1.346584\n",
      "LBFGS:    4 18:34:34        6.313034        1.217902\n",
      "LBFGS:    5 18:34:34        6.127949        0.945440\n",
      "LBFGS:    6 18:34:35        6.048857        0.964770\n",
      "LBFGS:    7 18:34:35        5.985114        1.174477\n",
      "LBFGS:    8 18:34:35        5.836227        1.468761\n",
      "LBFGS:    9 18:34:35        5.692513        1.501310\n",
      "LBFGS:   10 18:34:35        5.539249        1.814911\n",
      "LBFGS:   11 18:34:35        5.366181        1.560765\n",
      "LBFGS:   12 18:34:35        4.842599        1.351989\n",
      "LBFGS:   13 18:34:35        4.658264        1.306675\n",
      "LBFGS:   14 18:34:35        4.538569        1.194850\n",
      "LBFGS:   15 18:34:35        4.282097        1.025784\n",
      "LBFGS:   16 18:34:35        4.092666        0.798602\n",
      "LBFGS:   17 18:34:36        3.974083        0.663508\n",
      "LBFGS:   18 18:34:36        3.884914        0.575546\n",
      "LBFGS:   19 18:34:36        3.755246        0.474855\n",
      "LBFGS:   20 18:34:36        3.719079        0.436582\n",
      "LBFGS:   21 18:34:36        3.670767        0.422794\n",
      "LBFGS:   22 18:34:36        3.550363        0.426221\n",
      "LBFGS:   23 18:34:36        3.034488        0.411658\n",
      "LBFGS:   24 18:34:36        2.767441        0.306983\n",
      "LBFGS:   25 18:34:36        2.565219        0.306612\n",
      "LBFGS:   26 18:34:36        2.542810        0.193534\n",
      "LBFGS:   27 18:34:36        2.492869        0.177245\n",
      "LBFGS:   28 18:34:37        2.270108        0.151172\n",
      "LBFGS:   29 18:34:37        1.120496        0.133735\n",
      "LBFGS:   30 18:34:37        1.033953        0.046678\n",
      "       Step     Time          Energy          fmax\n",
      "LBFGS:    0 18:34:37       10.020816       12.682655\n",
      "LBFGS:    1 18:34:37        8.212910        6.250186\n",
      "LBFGS:    2 18:34:37        6.897683        2.365857\n",
      "LBFGS:    3 18:34:37        6.203907        1.594001\n",
      "LBFGS:    4 18:34:37        5.915850        1.107093\n",
      "LBFGS:    5 18:34:37        5.678482        1.088012\n",
      "LBFGS:    6 18:34:37        5.552660        1.068554\n",
      "LBFGS:    7 18:34:37        5.406758        1.360542\n",
      "LBFGS:    8 18:34:38        5.242342        1.595272\n",
      "LBFGS:    9 18:34:38        5.177490        1.111586\n",
      "LBFGS:   10 18:34:38        5.099910        1.196294\n",
      "LBFGS:   11 18:34:38        4.792512        1.321738\n",
      "LBFGS:   12 18:34:38        4.448299        1.277492\n",
      "LBFGS:   13 18:34:38        4.282586        0.903027\n",
      "LBFGS:   14 18:34:38        4.001500        0.933904\n",
      "LBFGS:   15 18:34:38        3.841534        0.817430\n",
      "LBFGS:   16 18:34:38        3.611658        0.736716\n",
      "LBFGS:   17 18:34:38        3.291496        0.567300\n",
      "LBFGS:   18 18:34:39        3.025290        0.416025\n",
      "LBFGS:   19 18:34:39        2.639725        0.342359\n",
      "LBFGS:   20 18:34:39        2.256284        0.291688\n",
      "LBFGS:   21 18:34:39        1.874056        0.254081\n",
      "LBFGS:   22 18:34:39        1.626133        0.211777\n",
      "LBFGS:   23 18:34:39        1.617049        0.175617\n",
      "LBFGS:   24 18:34:39        1.370041        0.131732\n",
      "LBFGS:   25 18:34:39        1.282717        0.111491\n",
      "LBFGS:   26 18:34:39        0.744037        0.052427\n",
      "LBFGS:   27 18:34:39        0.386582        0.057985\n",
      "LBFGS:   28 18:34:39        0.112794        0.039182\n",
      "       Step     Time          Energy          fmax\n",
      "LBFGS:    0 18:34:40        6.931758        3.900274\n",
      "LBFGS:    1 18:34:40        6.544069        2.079693\n",
      "LBFGS:    2 18:34:40        6.188074        1.329896\n",
      "LBFGS:    3 18:34:40        5.993612        1.144999\n",
      "LBFGS:    4 18:34:40        5.915998        1.160784\n",
      "LBFGS:    5 18:34:40        5.789020        1.068404\n",
      "LBFGS:    6 18:34:40        5.667225        1.144207\n",
      "LBFGS:    7 18:34:40        5.564221        1.067648\n",
      "LBFGS:    8 18:34:40        5.552577        1.135255\n",
      "LBFGS:    9 18:34:40        5.530295        1.034159\n",
      "LBFGS:   10 18:34:40        5.342979        1.997539\n",
      "LBFGS:   11 18:34:41        5.121457        2.192701\n",
      "LBFGS:   12 18:34:41        4.880833        1.668751\n",
      "LBFGS:   13 18:34:41        4.628169        1.113678\n",
      "LBFGS:   14 18:34:41        4.344510        0.815055\n",
      "LBFGS:   15 18:34:41        4.037597        0.728853\n",
      "LBFGS:   16 18:34:41        3.938328        0.815087\n",
      "LBFGS:   17 18:34:41        3.841941        0.870081\n",
      "LBFGS:   18 18:34:41        3.745354        0.863476\n",
      "LBFGS:   19 18:34:41        3.632611        0.789713\n",
      "LBFGS:   20 18:34:41        3.448122        0.624565\n",
      "LBFGS:   21 18:34:41        3.195235        0.411136\n",
      "LBFGS:   22 18:34:42        2.661796        0.220826\n",
      "LBFGS:   23 18:34:42        2.765926        0.259474\n",
      "LBFGS:   24 18:34:42        2.757211        0.192161\n",
      "LBFGS:   25 18:34:42        2.560416        0.155044\n",
      "LBFGS:   26 18:34:42        2.226578        0.141702\n",
      "LBFGS:   27 18:34:42        1.673947        0.138483\n",
      "LBFGS:   28 18:34:42        0.956835        0.095176\n",
      "LBFGS:   29 18:34:42        0.550570        0.047668\n",
      "       Step     Time          Energy          fmax\n",
      "LBFGS:    0 18:34:42        9.603795       10.443646\n",
      "LBFGS:    1 18:34:42        7.891695        5.256372\n",
      "LBFGS:    2 18:34:42        7.044978        1.976805\n",
      "LBFGS:    3 18:34:43        6.674068        1.291295\n",
      "LBFGS:    4 18:34:43        6.442400        1.188518\n",
      "LBFGS:    5 18:34:43        6.156201        1.313581\n",
      "LBFGS:    6 18:34:43        5.941834        1.315526\n",
      "LBFGS:    7 18:34:43        5.809573        1.610395\n",
      "LBFGS:    8 18:34:43        5.548028        1.707903\n",
      "LBFGS:    9 18:34:43        5.396400        1.883279\n",
      "LBFGS:   10 18:34:43        5.052439        2.199040\n",
      "LBFGS:   11 18:34:43        4.658689        1.354912\n",
      "LBFGS:   12 18:34:43        4.370564        0.784897\n",
      "LBFGS:   13 18:34:43        4.242237        0.987371\n",
      "LBFGS:   14 18:34:44        4.153451        1.055970\n",
      "LBFGS:   15 18:34:44        3.936067        0.970231\n",
      "LBFGS:   16 18:34:44        3.772023        0.783931\n",
      "LBFGS:   17 18:34:44        3.302153        0.528246\n",
      "LBFGS:   18 18:34:44        2.924971        0.337088\n",
      "LBFGS:   19 18:34:44        2.913304        0.223374\n",
      "LBFGS:   20 18:34:44        2.992669        0.178494\n",
      "LBFGS:   21 18:34:44        2.915266        0.185507\n",
      "LBFGS:   22 18:34:44        2.857783        0.178845\n",
      "LBFGS:   23 18:34:44        2.620588        0.160795\n",
      "LBFGS:   24 18:34:44        2.386734        0.131377\n",
      "LBFGS:   25 18:34:45        1.654998        0.119425\n",
      "LBFGS:   26 18:34:45        1.174259        0.092658\n",
      "LBFGS:   27 18:34:45        0.278830        0.080547\n",
      "LBFGS:   28 18:34:45       -0.736667        0.029735\n",
      "       Step     Time          Energy          fmax\n",
      "LBFGS:    0 18:34:45        7.506277        4.794408\n",
      "LBFGS:    1 18:34:45        6.999231        2.558032\n",
      "LBFGS:    2 18:34:45        6.551778        1.419532\n",
      "LBFGS:    3 18:34:45        6.290473        1.363324\n",
      "LBFGS:    4 18:34:45        6.206001        1.266517\n",
      "LBFGS:    5 18:34:45        6.103912        1.051546\n",
      "LBFGS:    6 18:34:46        5.955697        1.282728\n",
      "LBFGS:    7 18:34:46        5.836672        1.350810\n",
      "LBFGS:    8 18:34:46        5.806091        1.419973\n",
      "LBFGS:    9 18:34:46        5.715920        1.533812\n",
      "LBFGS:   10 18:34:46        5.401121        1.840751\n",
      "LBFGS:   11 18:34:46        5.055581        1.511941\n",
      "LBFGS:   12 18:34:46        4.792674        1.114631\n",
      "LBFGS:   13 18:34:46        4.531620        0.911433\n",
      "LBFGS:   14 18:34:46        4.400962        0.838791\n",
      "LBFGS:   15 18:34:46        4.260560        1.136885\n",
      "LBFGS:   16 18:34:46        4.123202        1.276767\n",
      "LBFGS:   17 18:34:47        4.002882        1.235648\n",
      "LBFGS:   18 18:34:47        3.855648        1.006726\n",
      "LBFGS:   19 18:34:47        3.671635        0.629457\n",
      "LBFGS:   20 18:34:47        3.592710        0.358156\n",
      "LBFGS:   21 18:34:47        3.621231        0.282688\n",
      "LBFGS:   22 18:34:47        3.595964        0.277371\n",
      "LBFGS:   23 18:34:47        3.533386        0.270865\n",
      "LBFGS:   24 18:34:47        3.490355        0.231947\n",
      "LBFGS:   25 18:34:47        3.209600        0.343972\n",
      "LBFGS:   26 18:34:47        3.044269        0.268974\n",
      "LBFGS:   27 18:34:47        2.850276        0.163297\n",
      "LBFGS:   28 18:34:48        2.636311        0.165382\n",
      "LBFGS:   29 18:34:48        1.966123        0.122322\n",
      "LBFGS:   30 18:34:48        0.408811        0.057235\n",
      "LBFGS:   31 18:34:48       -0.165027        0.049581\n",
      "       Step     Time          Energy          fmax\n",
      "LBFGS:    0 18:34:48        7.730400        4.288659\n",
      "LBFGS:    1 18:34:48        7.442163        1.829282\n",
      "LBFGS:    2 18:34:48        7.116853        1.709544\n",
      "LBFGS:    3 18:34:48        6.794564        1.460814\n",
      "LBFGS:    4 18:34:48        6.664184        1.486287\n",
      "LBFGS:    5 18:34:48        6.487654        1.585719\n",
      "LBFGS:    6 18:34:48        6.222558        1.404065\n",
      "LBFGS:    7 18:34:49        6.078682        1.983772\n",
      "LBFGS:    8 18:34:49        5.967072        1.899228\n",
      "LBFGS:    9 18:34:49        5.713893        1.820163\n",
      "LBFGS:   10 18:34:49        5.357399        2.400821\n",
      "LBFGS:   11 18:34:49        4.849597        2.126787\n",
      "LBFGS:   12 18:34:49        4.636357        1.538961\n",
      "LBFGS:   13 18:34:49        4.460705        0.887032\n",
      "LBFGS:   14 18:34:49        4.290203        0.793925\n",
      "LBFGS:   15 18:34:49        4.121719        0.898343\n",
      "LBFGS:   16 18:34:49        3.984326        0.981889\n",
      "LBFGS:   17 18:34:49        3.703089        0.949845\n",
      "LBFGS:   18 18:34:50        3.341997        0.794346\n",
      "LBFGS:   19 18:34:50        2.958908        0.504066\n",
      "LBFGS:   20 18:34:50        2.976330        0.220219\n",
      "LBFGS:   21 18:34:50        3.015349        0.163717\n",
      "LBFGS:   22 18:34:50        2.852454        0.168771\n",
      "LBFGS:   23 18:34:50        2.571561        0.132174\n",
      "LBFGS:   24 18:34:50        1.955936        0.086119\n",
      "LBFGS:   25 18:34:50        1.326087        0.064021\n",
      "LBFGS:   26 18:34:50        0.466123        0.046608\n",
      "       Step     Time          Energy          fmax\n",
      "LBFGS:    0 18:34:50       10.264864       13.892707\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "213847cf-a42f-41d3-85ee-11d5c90e4387",
   "metadata": {},
   "source": [
    "slab.get_chemical_formula()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9fa947df-ea15-497b-957e-02bc6fdc186f",
   "metadata": {},
   "source": [
    "from fairchem.core.models.model_registry import available_pretrained_models\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "baa5c71c-91dc-4e05-bbe4-ddbfab8d1b80",
   "metadata": {},
   "source": [
    "available_pretrained_models"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a5108478-09ba-40a9-bb22-2faf31495da7",
   "metadata": {},
   "source": [
    "from fairchem.core.models.model_registry import model_name_to_local_file\n",
    "checkpoint_path = model_name_to_local_file('EquiformerV2-153M-S2EF-OC20-All+MD', local_cache='/tmp/fairchem_checkpoints/')\n",
    "checkpoint_path"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f3d9404080ae113a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:HEA]",
   "language": "python",
   "name": "conda-env-HEA-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
